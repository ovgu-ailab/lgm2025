---
layout: default
title: Index
---

# Learning Generative Models
---------------------------------

Winter Semester 2025  
[Prof. Dr. Sebastian Stober](http://www.ai.ovgu.de/Staff/Stober.html)  
[Jens Johannsmeier, M.Sc.](http://www.ai.ovgu.de/Staff/Johannsmeier.html)  
Lecture: Thu 09:00-11:00; G29-307  
Exercise: Fri 09:00-11:00; G29-307

**Start of lectures:  Thursday, October 16th**

---

>_"What I cannot create, I do not understand."_  
>Richard Feynman

Deep Learning techniques have gained popularity and yielded astonishing results in a wide range of applications, like computer vision or speech recognition. In most of these applications, deep neural nets are trained in a supervised way, i.e., the network is trained to predict a particular label for high-dimensional data. In order to perform well, they need large amounts of data.

In many real-world applications, the amount of data is either limited or it is not annotated with the desired labels. For instance, training a deep neural network to reliably detect a malfunction in a nuclear power plant would require a lot of measurements during melt-down, which obviously is infeasible.

Generative models can be used to tackle such problems. They learn to represent the probability distribution over multiple variables from training data. While ordinary deep neural networks may discard any information unrelated to the desired prediction, generative models learn to represent the data in its entirety. As such, they can be applied to tasks like imputing missing values, repairing damaged data, detecting anomalies or generating new data from the learnt distribution.

### Course Content

The course will first focus on understanding and applying shallow and deep energy-based models as a particular type of generative models. Furthermore, the course will cover more recent generative models, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Autoregressive Models, Diffusion Models, and more. For implementation, we will use Python and TensorFlow.

This course requires active participation as it follows a "flipped classroom" design. You will prepare for contents before the class using selected text book chapters or recent publications. The in-class time will be used for discussions and for strengthening the understanding.

If you have got questions about the course, please contact [Sebastian Stober](mailto:stober@ovgu.de).


### Administrative Terms & Conditions (a.k.a. the "fine print")

([Link to LSF](https://lsf.ovgu.de/qislsf/rds?state=verpublish&status=init&vmfile=no&publishid=228345&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung) 
| [Link to Moodle](https://elearning.ovgu.de/course/view.php?id=19553) -- Course Password: LGMWS25)

#### Prerequisites for Attending

This is a very advanced course intended for students who have successfully taken the lecture "Introduction to Deep Learning" which is regularly taught alternatingly in the summer term, or "Deep Learning f√ºr Ingenieure" in the winter term. 
You need to know the concepts and techniques introduced there to be able to follow along. If you did not take this course but you think that you still have the required knowledge, please contact [Sebastian Stober](mailto:stober@ovgu.de).


#### Credits

The course belongs the to topic domain "practical computer science" and amounts to **5 credit points** or an equivalent of **150 hours**. 
Be prepared to spend that much time! 
If you are into the topic and want to go deeper, rather plan for some extra time - it's worth it!
Master students can obtain 6 credit points by completing an additional task of roughly 30 hours. 
(Details will be announced in class.)

