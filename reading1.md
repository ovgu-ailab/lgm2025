---
layout: default
title: Reading Assignment 1
id: reading1
---


# Reading Assignment 1: Graphical Models & Monte Carlo Methods

## Optional Reading: Probability Theory Refresher

Chapter 2 of the [Bishop Book](https://www.bishopbook.com/) covers important fundamentals that are essential for understanding the probabilistic approaches to deep learning we will focus on in this course. These should be known already from prior lectures. If you would like to refresh your knowledge, we recommend you skim/read through this chapter. 

## Graphical Models

The first important topic for this week are probabilistic graphical models for structured probability distributions and how they express dependence and independence. This is described in depth in Chapter 11. 
Section 11.3 can be skipped. The most import parts are Sections 11.1.1+2 and 11.2.2+3

## Sampling

The second topic for this week is how we can sample from probabilistic graphical models. This is explained in Chapter 14. Here, the most important part is Section 14.2 - specifically:
- Markov Chain Monte Carlo methods (in general)
- Gibbs Sampling
- Ancestral Sampling

## Further Alternative Reading

In earlier iterations of this course, we relied on specific sections of the [Deep Learning Book](https://www.deeplearningbook.org/) that also cover these topics. If you are interested, please refer to the [reading assignment from the 2024 class](https://ovgu-ailab.github.io/lgm2024/reading1.html).



